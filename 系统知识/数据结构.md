## 数据结构
学习数据结构，注意　代码 > 可视化思想和概念 > 书里的理论 > 公开课
应该先了解数据结构中常见的名词术语-->大概心里有个轮廓-->比如红黑树和AVL树的关系-->再去细看具体的细节-->去看代码实现，或者语言里的库实现，跑个例子试一下-->再去自己动手写一遍

书籍：
1.《数据结构与算法 C++描述》
    * 英文版 第三版
    * Author: Mark Allen Weiss
2. 《大话数据结构》
3. 《啊哈！算法》

代码：
* c 语言用起来太麻烦，往往会把注意力放到语法上而非数据结构本身
* c++的STL库用起来比较方便，要熟悉。

网站：
* VisuAlgo VisuAlgo中文
* Data Structure Visualizations
* 知乎

其他
* 公开课：清华大学学堂在线－数据结构
* 画图软件：Graphviz

## 《大话数据结构》笔记
算法的复杂性分析 O Omiga o omiga Theta

线性表（List）：
* Java中的ArrayList，Python中的 list []，c++中的数组和vector，lua中的table
* 必须的是相同的数据排列，且最多有一个前驱和后继
* 顺序存储就是数组，链式存储就是链表（单链表和双向链表）

栈和队列（Stack Queue）
* 栈也可以用顺序和链式两种实现方法
* 栈可以用于实现递归，如斐波那契数列；也可以拿来实现后缀表达式（逆波兰RPN），计算四则运算
* 队列也有两种实现（顺序和链式），也有循环队列来防止假溢出

串（String）
* string中比较大小是通过编码来做的，当且仅当长度相等，且每一位字符都相等。
* ASCII共8位二进制，256个字符，
* Unicode是4位16进制，如python里的 u'你好' 就是 u'\u4f60\u597d'，共65,536个字符
* 子串的定位称作是模式匹配->朴素的模式匹配->KMP模式匹配算法
* KMP算法避免了不必要的回溯，主串的指针i不动，子串的指针j回溯

树
* 树的基本概念
* 二叉树，树，森林的转化和遍历
* 哈夫曼树（Huffman）在数据压缩中的应用，整个二叉树中带权路径长度最小的树，就是哈夫曼树
* 哈夫曼树可以用来做编码

图
* 图的概念和表示方法，邻接矩阵，邻接表，十字链表
* 深度优先遍历（递归） && 广度优先遍历（队列）
* 最小生成树：从带权图中以最小的总权值，遍历所有的节点；Prim算法（适用于稠密图）和Kruskal算法（适用于稀疏图）
* 查找最短路径：Dijkstra算法（其实用了广度优先遍历，单源到其他点，O(n^2)），Floyd算法（所有点到所有点，O(n^3)）

查找和搜索
* 无序表->线性查找，顺序查找
* 有序表->折半查找
* 建立索引，包括线性索引，树形索引和多级索引
* 线性索引包括分块索引，倒排索引；二叉排序树（左小右大）；平衡二叉排序树（AVL树）
* 平衡树的定义是左右子树深度差值不超过１，平衡是通过旋转得到的（单旋和双旋）
* B 树，B+ 树

散列表（哈希表）
* 通过哈希函数，把key,value存储在哈希表里
* 处理散列冲突，rehash

排序
* 冒泡排序 Bubble Sort　O(n^2) 稳定　每次在剩下的序列里找最大的（即冒泡）
* 选择排序 Select Sort　O(n^2) 稳定　每次选择一个最大的，不交换
* 直接插入排序 Insert Sort O(n^2)　稳定 循环一边，把元素插入到合适位置，其他元素后移一位
* 希尔排序 Hell Sort　O(nlogn) 非稳定　
    * 实质是分组插入排序， 每次分组大小减半直到为2，参考百度百科
    * 是直接插入排序的改进，因为直接插入排序只能和相邻的元素进行交换，而希尔排序可以进行远距离的比较和交换。
    * 比如初始分组步长为 5，那么相邻差5个距离的数字构成同一组，组内的数字进行插入排序。
    * 接着步长减少一半，再次分组插入排序，直到步长为 1
* 堆排序 Heap Sort　O(nlogn) 不稳定　最小堆：所有根节点都小于其子节点的完全二叉树。每次删除最小的元素
* 归并排序 Merge Sort　O(nlogn) 稳定 分而治之的思想，合并两个有序的列表，复杂度为O(n)
* 快速排序 Quick Sort　O(nlogn) 不稳定　最快　用了分治法的思想
    * 从队列里取一个基准数（pivot），小的都丢左边，大的都丢右边。对左右自区间递归操作。
    * 取基准不是取中间的数，而是从头开始，挖坑填坑，参考博文。
    * pivot = a[0]; i = 0
    * 从右边找一个比 pivot 小的数，填上 a[i] 的位置，记录位置为 j
    * 从左边找一个比 pivot 大的数，填上 a[j] 的位置，记录位置为 i
    * 重复 2,3步骤直到 i = j，把 pivot 填充到 a[i] 位置。返回 i 的位置
    * 除了挖坑填坑，剑指offer里还有别的实现 Partition 的方法，基于交换，一次循环即可。
    * 具体方法是，把最后一个数当做是 pivot，
* 桶排序 Bucket Sort 即计数排序
    * 挺有用的，如果要排序的数大致在一个范围内，可以用一个定长的数组来记录每个数字
    * 如果数字不重复，还可以用 bit 来操作，这样对比 int 数组，节省了 32 倍！
    * 取位图（bit）和 int 数组之间的这种，可以用几个 bit 来表示数字。bit 的数量取决于出现词数的最大值。
* 外部排序 External Sort 即大文件无法全部以此加载到内存中，常用的排序算法失效；可以考虑分而治之，每次只排序部分的数字，然后归并到最终的那个文件中。

学堂在线课程 清华大学《数据结构下》

串 String
* 串的前缀 S.prefix(k) = S[0, k) 是特殊的字串，表示前k个字母；
* 同理后缀 S.suffix(k) = S[n-k, n) 表示后k个字母
* 空串是任何串的子串，前缀和后缀
* 模式匹配：蛮力匹配，逐一尝试匹配的位置。
* kmp算法，构建查询表，next[0, m]，在任意位置P[j]处失败后，将j替换为next[j]；注意这里的主串i位置不变。
* j <0，即j==-1时，i，j同时自增。否则只是j变化，因为i永远不会回溯。
* 构建next表的步骤是，next[j] = str(i,j-1){前缀和后缀的最大公共字串的长度}

## 《数据结构与算法 C++描述》

二分搜索树
* Binary Search Tree，BST 二分搜索树，定义为左节点<根节点<右节点的二叉树，
* 子树递归成立，节点中没有重复的点，节点必须是可以比较大小的
* 二分搜索树的查找和插入的效率较高
* findMin 最左边的子树是最小的 ；findMax 最右边的子树是最大的
* 插入的效率是树的高度，一般是O(logn)，插入到叶子结点
* 删除是最麻烦的，考虑
* 没有子节点，直接删除；
* 只有一个子节点，直接用子节点代替（见 P131，Figure 4.24）
* 有两个子节点，找到右子树中的最小值（findMin）顶替（顶替=删除+覆盖）

AVL树
* Adelson-Velskii and Landis Tree 是一种特殊的BST，又叫平衡二叉树
* 平衡性限制了左右子树的高度差不超过一，且递归成立；保障了树的高度不会太高
* 插入操作会改变AVL树的平衡性，需要通过旋转来纠正
* case1 在左子树插入左孩子 case4 在右子树插入右孩子 都需要单旋 single rotation
* 就case1来讲，单旋就是把左子树提升为根节点，左子树的右孩子接到原根节点的左子树上
* 见 P139 Figure 4.34 的 case1 的单旋，改变两个指针就可以了
* case2 在左子树插入右孩子 case3 在右子树插入左孩子 都需要双旋 double rotation
* 就case2而言，双旋把孙子节点变成了根节点，根节点变成其左子树。更深的就太复杂了。
* 见P143的两种情况，有点麻烦

Splay Tree 伸展树
* 伸展树也是一种二分查找树，但是连续查找（如，m次）的效率更高，在mlogn级别
* 每次查找结束后，对伸展树进行重构，把查找到的节点，通过旋转变成根节点。这样的话，经常访问的节点的深度不会太深。
* zig --> 进行单旋转 single rotation
* zig-zag --> 进行双旋转 double rotation
* zig-zig --> 进行 zig-zig 操作 （拎起来）

Red-Black Tree 红黑树
* 红黑树也是一种平衡的二叉搜索树，但是平衡要求和AVL树不太一样
* 红黑树始终要满足下面的五个性质
    1. 每个节点都必须染成红色或者黑色的一种
    2. 根节点是黑色的
    3. 所有的叶子节点是黑色的
    4. 每个红色节点必须有两个黑色节点
    5. 从任意节点都每个叶子节点的所有简单路径都包含相同数目的黑色节点
* 具体的图示参考维基百科词条
* 插入和删除操作会破坏红黑树的性质，可以通过树的旋转和改变树的颜色来调整。
* TODO：红黑树的概念、左旋右旋的方式、分析出查找和插入的平均算法复杂度和最好最坏时的算法复杂度

Trie Tree（字典树）与 Suffix Tree（后缀树）
* Trie来源于单词retrieve，读作try，常用来做字符串的查询。
* 本质上，Trie是一棵存储多个字符串的树，边代表字符，一个节点的路径形成字符串。
* 后缀树，就是包含一则字符串的所有后缀（和前缀相反）的压缩Trie
* 如Friday的所有后缀是，Friday, riday, iday, day, ay, y, $
* 即把所有的字符串的后缀（包括本身和空串），添加到Trie Tree中去，再压缩一下（没有分叉的路径压缩成一条边）
* 广义后缀树（Generalized Suffix Tree）把后缀树拓展到多个单词上去。

Segment Tree 线段树
* 线段树是一个二叉平衡搜索树，每个节点表示一个区间(a, b)，其中 b-a 为该区间的长度。

B树，B+树，B-树，B*树
* B树和其拓展B+树，B*树等，在文件系统和数据库的设计中用到的较多。
* B树和B-树指的是一个东西，都是同一种多叉平衡查找树，
    * B树必须满足下面几个性质（假设该B树的阶为M）：
        * 每个节点最多有 M 个子树；
        * 根节点至少有两个子节点
        * 除了根节点，其他的非叶子节点至少有 [M / 2] 个子节点；
        * 非叶子结点有 k 个子节点，k - 1 个 key；
        * 所有的叶子节点在同一层，但是没有数据。
* B+树
    * 子节点的个数k，k<=M等于关键码的个数k,k<=L
    * 插入操作：直接插入，叶节点满了则分裂出一个子树；父节点满了则分列父节点
    * 删除和插入相反，删掉后的叶节点，可能会和左边的兄弟地道一起挤到一起以满足B树的性质；再删除下去，父节点也会被删掉。
* 常见面试题
    * 介绍下B树？答：B树是一种改进的二叉搜索树，通过尽量降低树的高度来减少文件IO索引的次数。常用在文件系统，数据库索引中
    * B+树相比于B树有什么优点？答：所有的数据都存放在叶子节点，空间利用率更高，树的高度更低。

R 树
* 是 B 树的高维扩展，参考 python 的库：rtree；

优先队列Priority Queues（堆Heap）（这里只讲二叉堆，也是堆的默认实现方式；最大堆和最小堆同理）
* 堆是一个完全二叉树，因此可以用数组来存储该树。下标为 i 的节点的左右子树的下标为2i+1，2i+2
* 堆中最小的数永远在根节点处，根节点总小于子树，且递归成立 
* 建立最小堆的过程：先建立数组，随机存储；
* 然后自顶向下，逐个调整节点到满足父节点小于左右子树（可以是逐层遍历，广搜？），进行shiftdown操作。
* shiftdown 是说，如果左右子树的某个节点小于该节点，把较小的那个往上渗透，直到合适的位置或者根节点。
* 插入操作：由于是完全二叉树，在最后一个叶节点处添加一个hole，即虚拟节点，然后开始“向上渗透（percolate up，shiftup）”（就是说，如果根节点小于这个虚拟节点，那么把根节点拉下来，hole向上渗透）到合适位置 ， 把待插入的值赋给这个虚拟节点。
* delMin操作：作为最小堆，不会提供任意元素的删除操作，而是只有最小的那个可以删除。删除最小值即删除根节点，把最后一个叶节点 p 拿掉。此时因为根节点已经空了，我们从上往下，找一个合适空缺把 p 填进去。

哈希表（散列表，Hash Table）
* 若关键字（key）为 k，则把值放在 f(k) 的位置，其中 f 是哈希函数（散列函数）；一种简单的哈希函数设计是直接 key_value % hash_table_size
* 不同的 key 可能会得到相同的哈希值，这种现象叫做冲突（collision）；好的哈希函数会尽量减少冲突。
* 处理冲突的方法：
* 数组 + 链表 ？ // 把相同哈希值的 key 用链表串起来
* 缓冲区，把冲突的全都放在缓冲区里
* 线性探测（linear probing），如果在位置为 k 的地方冲突了，可以继续在 k+1, k-1, k+2, k -2... 的位置继续找，直到找到该关键字，或者寻空。
* 再哈希（re-hash）冲突了就换一种哈希函数

并查集算法 Union-Find Algorithm
* 同一个集合可以用一棵树来表示，因此可以用根节点的index来代表这个树
* find函数，用来查找该节点的root，等于自身则说明是root，find递归终止。
* union函数，合并两个节点，则把root置为同一个即可。

算法系列：
* 贪心算法
* 分而治之
* 动态规划
* 回溯法
