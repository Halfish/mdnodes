redis 分布式锁

参考：[分布式锁的实现之 redis 篇
](https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/)

## 最简单版本的分布式锁

redis 命令
- 加锁操作：`SETNX key value`
    - 通过设置 redis 中的某个 key 来实现加锁。
    - SETNX = set key if not exist
- 解锁操作：`DEL key`
    - 通过删除某个键值实现解锁
- 设置超时：`EXPIRE key timeout`
    - 通过设置超时避免资源永远被占用

但是上面的操作有些问题，SETNX 和 EXPIRE 是两个操作，不是原子性。如果后者没有执行会造成资源死锁。

不过现在 redis >= 2.6.12 已经支持设置键值的同时设置超时时间，这个问题已经不存在了。

```bash
# 直接加锁
set lock_name thread_name nx ex 100

# 释放锁
del lock_name
```

## 问题1：锁的误解除

想象下这个场景：
1. A、B 同用一个资源
2. A 先加锁，但是超时后琐失效，此时 A 仍然没有完成业务。
3. B 看到没有锁，认为资源已经释放，会加锁并执行业务
4. A 执行完业务，会对解锁释放资源，但是释放的其实是 B 的锁。
5. B 执行完任务想解锁，发现锁已经被 A 解除了，一脸懵逼。

总结来说，就是两个程序用了同一个资源，可能会产生锁的误接触。当业务逻辑的时间不超过设定的超时时间就不会有问题，但是生产环境很难保证。

**解决方法**：每个程序加一个标识符，比如 UUID 标识。解锁前先看看是不是自己的锁。

## 问题2：分布式锁的原子性问题

上述改进点仍然有缺陷，即在判断是否是自己的锁和释放锁之间，可能会阻塞（比如full GC），此时有可能超时释放锁，仍然再存数据竞争的问题。

**解决方法**：用 lua 脚本编写上面的逻辑（判断是不是自己的锁，然后删除锁），脚本执行是原子性的。

执行 lua 脚本示例：
```bash
# 执行 lua 脚本，相当于执行 `SET name bruce`
eval "redis.call('set', 'name', 'bruce')" 0

# 带参数的脚本
eval "return redis.call('set', KEYS[1], ARGV[1])" 1 name bruce
```

lua脚本的逻辑
```lua
if (redis.call('get', KEYS[1]) == ARGV[1]) then
    return redis.call('del', KEYS[1])
end
return 0
```


## 红锁：Redssion

上面的分布式锁仍然存在问题
1. 不可重入：函数A调用函数B，两个函数都需要用同一把锁，此时会死锁。
2. 不可重试：没有重试机制，等等可能锁就释放了。
3. 超时释放：超时释放锁可能会有问题。
4. Redis主从一致性：Redis分布式集群存在同步延迟。

可以用 Redission 解决，这个是基于 Java 封装的分布式锁。

**1. 可重入锁的原理**
- 原本用的是 set key value，现在用 mset key field count
- 每次重复一次，记录一下次数，直到次数为 0，再删除锁。

**2. 重试锁的原理**
- 先尝试获取所，如果失败了，则订阅一下释放锁的事件。直到超时。

**3. 超时释放的原理（看门狗机制）**
- 启动一个看门狗线程，不断刷新过期时间，永远续期
- 如果当前进程挂了，那么看门狗线程也会挂，就不会续期，也就会执行过期。
- 释放锁时，记得停止看门狗线程。

**4. 主从一致性问题**
- 设置多个主节点，获取锁也要在每个主节点上获取，叫做连锁（`MultiLock`）。
- 这样当一个主节点宕机，也不会影响整体的分布式锁。
